{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "e0Ft8Ck2OuQ4",
        "UY1ZSJN9O-8f",
        "lH0_F1MY3lg-"
      ],
      "authorship_tag": "ABX9TyPgVD1MvqwNMDXtrvnzbq5d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YagmurTaze/OCR-ICR/blob/main/1_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "e0Ft8Ck2OuQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dense\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "NHTCEKNAgY2B"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBh5bP7EOzS6",
        "outputId": "5e6e75fb-a202-43c2-d8d8-efb2fb552644"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess"
      ],
      "metadata": {
        "id": "UY1ZSJN9O-8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Verilerinizi yükleyin\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "path = '/content/drive/MyDrive/Datasets/TURKISH CHARACTERS'\n",
        "\n",
        "dir_list = os.listdir(path)\n",
        "for i in dir_list:\n",
        "    dir = os.path.join(path, i)\n",
        "    file_list = os.listdir(dir)\n",
        "    for j in file_list:\n",
        "        files = os.path.join(dir, j)\n",
        "        img = cv2.imread(files)\n",
        "        img = cv2.resize(img, (64, 64))\n",
        "        img = np.array(img, dtype=np.float32)\n",
        "        img = img / 255\n",
        "        images.append(img)\n",
        "        labels.append(i)"
      ],
      "metadata": {
        "id": "-PRzXffwQr5_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(images)\n",
        "y = np.array(labels)"
      ],
      "metadata": {
        "id": "_L04QX5KPAl0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Model"
      ],
      "metadata": {
        "id": "xtSeGYnK-68x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(images)\n",
        "y = np.array(labels)\n",
        "\n",
        "# Etiketleri kodlayın\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "# Veriyi eğitim ve test setlerine ayırın\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Modeli oluşturun\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dense(units=68, activation='softmax'))"
      ],
      "metadata": {
        "id": "137V95IulBVK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modeli derleyin\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Modeli eğitin\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=16, epochs=5)\n",
        "\n",
        "# Modeli kaydedin\n",
        "model.save(\"byLettermodel.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POPW-4gLlsig",
        "outputId": "00093ac4-dd62-4bdf-ab97-54780971621a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "340/340 [==============================] - 27s 74ms/step - loss: 3.1132 - accuracy: 0.2131 - val_loss: 1.8150 - val_accuracy: 0.4853\n",
            "Epoch 2/5\n",
            "340/340 [==============================] - 25s 75ms/step - loss: 1.3158 - accuracy: 0.6026 - val_loss: 1.1006 - val_accuracy: 0.6691\n",
            "Epoch 3/5\n",
            "340/340 [==============================] - 25s 73ms/step - loss: 0.8185 - accuracy: 0.7200 - val_loss: 0.9573 - val_accuracy: 0.6978\n",
            "Epoch 4/5\n",
            "340/340 [==============================] - 26s 77ms/step - loss: 0.6212 - accuracy: 0.7757 - val_loss: 0.8571 - val_accuracy: 0.7213\n",
            "Epoch 5/5\n",
            "340/340 [==============================] - 25s 73ms/step - loss: 0.4892 - accuracy: 0.8143 - val_loss: 0.8329 - val_accuracy: 0.7301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "lH0_F1MY3lg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"byLettermodel.h5\")"
      ],
      "metadata": {
        "id": "TwkIUr-URdCR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Test edilecek resmi yükleyin\n",
        "test_image = image.load_img('/content/C1.png', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "\n",
        "# Tahmin yapma\n",
        "result = model.predict(test_image)\n",
        "\n",
        "predicted_class_index = np.argmax(result)\n",
        "alphabet = '0123456789ABCÇDEFGĞHIİJKLMNOÖPRSŞTUÜVYZabcçdefgğhıijklmnoöprsştuüvyz'\n",
        "predicted_letter = alphabet[predicted_class_index]\n",
        "\n",
        "print(\"Tahmin edilen harf:\", predicted_letter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R06rfsHfRjwb",
        "outputId": "7c7f26ba-09be-4a8b-a8a8-09f460555762"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 116ms/step\n",
            "Tahmin edilen harf: C\n"
          ]
        }
      ]
    }
  ]
}