{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "uajclYh_Ob5u",
        "a7vgQfkFOo6d",
        "Edj5ozXSR2pC",
        "pu_minQMR9aR",
        "hhsAPQJBSGLZ",
        "KhWy-D5YSTd6"
      ],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyM5hufFfqZkoLmrQHwXO1Mq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YagmurTaze/OCR-ICR/blob/main/3_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "uajclYh_Ob5u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6aNLBEVpOVU5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Bidirectional, LSTM, Dense, Lambda, Activation, BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l03XApHMOeFK",
        "outputId": "5e67da0e-6a94-437c-ab89-5902432d9c49"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Dataset"
      ],
      "metadata": {
        "id": "Q5_HjMioOfqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import pandas as pd\n",
        "\n",
        "# Excel dosyasını oku\n",
        "#excel_file = '/content/validation.xlsx'\n",
        "#df = pd.read_excel(excel_file)\n",
        "\n",
        "# CSV olarak kaydet (UTF-8 kodlaması ile)\n",
        "#csv_file = 'validation.csv'\n",
        "#df.to_csv(csv_file, index=False, encoding='utf-8')"
      ],
      "metadata": {
        "id": "fR2lTHWpmF3p"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/train.csv')\n",
        "valid = pd.read_csv('/content/validation.csv')"
      ],
      "metadata": {
        "id": "S1lRP5EDmTrE"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for i in range(6):\n",
        "    ax = plt.subplot(2, 3, i+1)\n",
        "    img_dir = '/content/drive/MyDrive/Datasets/WORDS OCR/train/'+train.loc[i, 'FILENAME']\n",
        "    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
        "    plt.imshow(image, cmap = 'gray')\n",
        "    plt.title(train.loc[i, 'IDENTITY'], fontsize=12)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.subplots_adjust(wspace=0.2, hspace=-0.8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "H-ABpOajmmrp",
        "outputId": "b083426f-d20a-4a5e-850f-290c291a9426"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1000 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = 7196\n",
        "valid_size= 800"
      ],
      "metadata": {
        "id": "PCEM5WzSmpCH"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess"
      ],
      "metadata": {
        "id": "p61xWj7umvBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(img):\n",
        "    (h, w) = img.shape\n",
        "\n",
        "    final_img = np.ones([64, 256])*255 # blank white image\n",
        "\n",
        "    # crop\n",
        "    if w > 256:\n",
        "        img = img[:, :256]\n",
        "\n",
        "    if h > 64:\n",
        "        img = img[:64, :]\n",
        "\n",
        "\n",
        "    final_img[:h, :w] = img\n",
        "    return cv2.rotate(final_img, cv2.ROTATE_90_CLOCKWISE)"
      ],
      "metadata": {
        "id": "PzWLvTD0OhkG"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = []\n",
        "\n",
        "for i in tqdm(range(train_size)):\n",
        "    img_dir = '/content/drive/MyDrive/Datasets/WORDS OCR/train/'+train.loc[i, 'FILENAME']\n",
        "    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
        "    image = preprocess(image)\n",
        "    image = image/255.\n",
        "    train_x.append(image)"
      ],
      "metadata": {
        "id": "uQEV69jpdD-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_x = []\n",
        "\n",
        "for i in tqdm(range(valid_size)):\n",
        "    img_dir = '/content/drive/MyDrive/Datasets/WORDS OCR/val/'+valid.loc[i, 'FILENAME']\n",
        "    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
        "    image = preprocess(image)\n",
        "    image = image/255.\n",
        "    valid_x.append(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCXzo-UxOkBV",
        "outputId": "16b555db-5c85-4f70-eac0-47ec755dffd0"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 800/800 [05:45<00:00,  2.31it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(valid_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLaddCj9UwHk",
        "outputId": "b5b1eb91-faf7-42ce-d2be-2d3ad42bc528"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "800"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_x listesini numpy array olarak kaydetme\n",
        "train_x_array = np.array(train_x)\n",
        "np.save('/content/drive/MyDrive/Datasets/WORDS OCR/train_x.npy', train_x_array)\n",
        "\n",
        "# valid_x listesini numpy array olarak kaydetme\n",
        "valid_x_array = np.array(valid_x)\n",
        "np.save('/content/drive/MyDrive/Datasets/WORDS OCR/valid_x.npy', valid_x_array)"
      ],
      "metadata": {
        "id": "k1FbHNU4QzNi"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kaydedilmiş numpy array dosyasını yükleme\n",
        "train_x_array = np.load('/content/drive/MyDrive/Datasets/TURKISH WORDS/train_x.npy')\n",
        "train_x = train_x_array.tolist()\n",
        "\n",
        "valid_x_array = np.load('/content/drive/MyDrive/Datasets/TURKISH WORDS/valid_x.npy')\n",
        "valid_x = valid_x_array.tolist()"
      ],
      "metadata": {
        "id": "mAbohwshQ9HS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2"
      ],
      "metadata": {
        "id": "a7vgQfkFOo6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = np.array(train_x).reshape(-1, 256, 64, 1)\n",
        "valid_x = np.array(valid_x).reshape(-1, 256, 64, 1)"
      ],
      "metadata": {
        "id": "O1Sjg4LWOnhZ"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alphabets = u\"ABCÇDEFGĞHIİJKLMNOÖPRSŞTUÜVYZabcçdefgğhıijklmnoöprsştuüvyz0123456789\\\".,-':;()?/!+& \"\n",
        "max_str_len = 24 # max length of input labels\n",
        "num_of_characters = len(alphabets) + 1 # +1 for ctc pseudo blank\n",
        "num_of_timestamps = 64 # max length of predicted labels\n",
        "\n",
        "\n",
        "def label_to_num(label):\n",
        "    label_num = []\n",
        "    for ch in label:\n",
        "        label_num.append(alphabets.find(ch))\n",
        "\n",
        "    return np.array(label_num)\n",
        "\n",
        "def num_to_label(num):\n",
        "    ret = \"\"\n",
        "    for ch in num:\n",
        "        if ch == -1:  # CTC Blank\n",
        "            break\n",
        "        else:\n",
        "            ret+=alphabets[ch]\n",
        "    return ret"
      ],
      "metadata": {
        "id": "XVivMZyIOsL3"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'ABC ?'\n",
        "print(name, '\\n',label_to_num(name))"
      ],
      "metadata": {
        "id": "uVej_fFxOuoH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "664674a0-d865-4e74-deed-1fce1f87497d"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ABC ? \n",
            " [ 0  1  2 82 77]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = np.ones([train_size, max_str_len]) * -1\n",
        "train_label_len = np.zeros([train_size, 1])\n",
        "train_input_len = np.ones([train_size, 1]) * (num_of_timestamps-2)\n",
        "train_output = np.zeros([train_size])\n",
        "\n",
        "for i in range(train_size):\n",
        "    train_label_len[i] = len(train.loc[i, 'IDENTITY'])\n",
        "    train_y[i, 0:len(train.loc[i, 'IDENTITY'])]= label_to_num(train.loc[i, 'IDENTITY'])"
      ],
      "metadata": {
        "id": "PLbJIE28Ov3d"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_y = np.ones([valid_size, max_str_len]) * -1\n",
        "valid_label_len = np.zeros([valid_size, 1])\n",
        "valid_input_len = np.ones([valid_size, 1]) * (num_of_timestamps-2)\n",
        "valid_output = np.zeros([valid_size])\n",
        "\n",
        "for i in range(valid_size):\n",
        "    valid_label_len[i] = len(valid.loc[i, 'IDENTITY'])\n",
        "    valid_y[i, 0:len(valid.loc[i, 'IDENTITY'])]= label_to_num(valid.loc[i, 'IDENTITY'])"
      ],
      "metadata": {
        "id": "_dFDe3yfOxPp"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('True label : ',train.loc[100, 'IDENTITY'] , '\\ntrain_y : ',train_y[100],'\\ntrain_label_len : ',train_label_len[100],\n",
        "      '\\ntrain_input_len : ', train_input_len[100])"
      ],
      "metadata": {
        "id": "dLiBsml8Oxs9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e33f3ed-7ca0-4cd2-90ab-745161387354"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True label :  istemiştir. \n",
            "train_y :  [40. 50. 52. 34. 44. 40. 51. 52. 40. 49. 69. -1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1.] \n",
            "train_label_len :  [11.] \n",
            "train_input_len :  [62.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Model"
      ],
      "metadata": {
        "id": "Edj5ozXSR2pC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = Input(shape=(256, 64, 1), name='input')\n",
        "\n",
        "inner = Conv2D(32, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(input_data)\n",
        "inner = BatchNormalization()(inner)\n",
        "inner = Activation('relu')(inner)\n",
        "inner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)\n",
        "\n",
        "inner = Conv2D(64, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)\n",
        "inner = BatchNormalization()(inner)\n",
        "inner = Activation('relu')(inner)\n",
        "inner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)\n",
        "inner = Dropout(0.3)(inner)\n",
        "\n",
        "inner = Conv2D(128, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)\n",
        "inner = BatchNormalization()(inner)\n",
        "inner = Activation('relu')(inner)\n",
        "inner = MaxPooling2D(pool_size=(1, 2), name='max3')(inner)\n",
        "inner = Dropout(0.3)(inner)\n",
        "\n",
        "# CNN to RNN\n",
        "inner = Reshape(target_shape=((64, 1024)), name='reshape')(inner)\n",
        "inner = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)\n",
        "\n",
        "## RNN\n",
        "inner = Bidirectional(LSTM(256, return_sequences=True), name = 'lstm1')(inner)\n",
        "inner = Bidirectional(LSTM(256, return_sequences=True), name = 'lstm2')(inner)\n",
        "\n",
        "## OUTPUT\n",
        "inner = Dense(num_of_characters, kernel_initializer='he_normal',name='dense2')(inner)\n",
        "y_pred = Activation('softmax', name='softmax')(inner)\n",
        "\n",
        "model = Model(inputs=input_data, outputs=y_pred)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "gtHnnB4XR1-v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "082b1986-49cc-466e-e13c-bca5b96619a5"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 256, 64, 1)]      0         \n",
            "                                                                 \n",
            " conv1 (Conv2D)              (None, 256, 64, 32)       320       \n",
            "                                                                 \n",
            " batch_normalization_9 (Bat  (None, 256, 64, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 256, 64, 32)       0         \n",
            "                                                                 \n",
            " max1 (MaxPooling2D)         (None, 128, 32, 32)       0         \n",
            "                                                                 \n",
            " conv2 (Conv2D)              (None, 128, 32, 64)       18496     \n",
            "                                                                 \n",
            " batch_normalization_10 (Ba  (None, 128, 32, 64)       256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 128, 32, 64)       0         \n",
            "                                                                 \n",
            " max2 (MaxPooling2D)         (None, 64, 16, 64)        0         \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 64, 16, 64)        0         \n",
            "                                                                 \n",
            " conv3 (Conv2D)              (None, 64, 16, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_11 (Ba  (None, 64, 16, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 64, 16, 128)       0         \n",
            "                                                                 \n",
            " max3 (MaxPooling2D)         (None, 64, 8, 128)        0         \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 64, 8, 128)        0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 64, 1024)          0         \n",
            "                                                                 \n",
            " dense1 (Dense)              (None, 64, 64)            65600     \n",
            "                                                                 \n",
            " lstm1 (Bidirectional)       (None, 64, 512)           657408    \n",
            "                                                                 \n",
            " lstm2 (Bidirectional)       (None, 64, 512)           1574912   \n",
            "                                                                 \n",
            " dense2 (Dense)              (None, 64, 84)            43092     \n",
            "                                                                 \n",
            " softmax (Activation)        (None, 64, 84)            0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2434580 (9.29 MB)\n",
            "Trainable params: 2434132 (9.29 MB)\n",
            "Non-trainable params: 448 (1.75 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the ctc loss function\n",
        "def ctc_lambda_func(args):\n",
        "     y_pred, labels, input_length, label_length = args\n",
        "\n",
        "     y_pred = y_pred[:, 2:, :]\n",
        "     return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
      ],
      "metadata": {
        "id": "yrBfz_1GR5nb"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = Input(name='gtruth_labels', shape=[max_str_len], dtype='float32')\n",
        "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
        "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
        "\n",
        "ctc_loss = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
        "model_final = Model(inputs=[input_data, labels, input_length, label_length], outputs=ctc_loss)"
      ],
      "metadata": {
        "id": "LzUmdjaUR7DX"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "pu_minQMR9aR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = ['accuracy']\n",
        "\n",
        "model_final.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=Adam(learning_rate = 0.0001),metrics=metrics)\n",
        "\n",
        "model_final.fit(x=[train_x, train_y, train_input_len, train_label_len], y=train_output,\n",
        "                validation_data=([valid_x, valid_y, valid_input_len, valid_label_len], valid_output),\n",
        "                epochs=50, batch_size=128)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnWW72Kscbon",
        "outputId": "179fdc31-f84e-4d92-864e-9272e3a12345"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "57/57 [==============================] - 14s 117ms/step - loss: 53.6361 - accuracy: 0.0000e+00 - val_loss: 32.6994 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "57/57 [==============================] - 5s 80ms/step - loss: 23.4886 - accuracy: 0.0000e+00 - val_loss: 24.0697 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "57/57 [==============================] - 4s 77ms/step - loss: 22.0332 - accuracy: 0.0000e+00 - val_loss: 22.2525 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "57/57 [==============================] - 4s 77ms/step - loss: 21.5114 - accuracy: 0.0000e+00 - val_loss: 21.7060 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "57/57 [==============================] - 4s 78ms/step - loss: 21.1869 - accuracy: 0.0000e+00 - val_loss: 21.4038 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "57/57 [==============================] - 4s 76ms/step - loss: 20.9684 - accuracy: 0.0000e+00 - val_loss: 21.0435 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "57/57 [==============================] - 4s 78ms/step - loss: 20.7776 - accuracy: 0.0000e+00 - val_loss: 20.8121 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "57/57 [==============================] - 4s 77ms/step - loss: 20.6171 - accuracy: 0.0000e+00 - val_loss: 20.6211 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "57/57 [==============================] - 4s 77ms/step - loss: 20.4365 - accuracy: 0.0000e+00 - val_loss: 20.4398 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "57/57 [==============================] - 5s 81ms/step - loss: 20.2541 - accuracy: 0.0000e+00 - val_loss: 20.1508 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "57/57 [==============================] - 4s 76ms/step - loss: 20.0463 - accuracy: 0.0000e+00 - val_loss: 19.9464 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "57/57 [==============================] - 4s 76ms/step - loss: 19.7062 - accuracy: 0.0000e+00 - val_loss: 19.8454 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "57/57 [==============================] - 4s 78ms/step - loss: 19.3769 - accuracy: 0.0000e+00 - val_loss: 19.0363 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "57/57 [==============================] - 4s 78ms/step - loss: 18.8906 - accuracy: 0.0000e+00 - val_loss: 18.5287 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "57/57 [==============================] - 4s 77ms/step - loss: 18.5427 - accuracy: 0.0000e+00 - val_loss: 18.2243 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "57/57 [==============================] - 4s 78ms/step - loss: 18.1299 - accuracy: 0.0000e+00 - val_loss: 18.2203 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "57/57 [==============================] - 4s 77ms/step - loss: 17.7843 - accuracy: 0.0000e+00 - val_loss: 17.6712 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "57/57 [==============================] - 4s 77ms/step - loss: 17.3866 - accuracy: 0.0000e+00 - val_loss: 17.0827 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "57/57 [==============================] - 5s 79ms/step - loss: 17.0108 - accuracy: 0.0000e+00 - val_loss: 16.7572 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "57/57 [==============================] - 4s 77ms/step - loss: 16.5864 - accuracy: 0.0000e+00 - val_loss: 16.3769 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "57/57 [==============================] - 4s 77ms/step - loss: 16.0830 - accuracy: 0.0000e+00 - val_loss: 15.8776 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "57/57 [==============================] - 4s 78ms/step - loss: 15.5205 - accuracy: 0.0000e+00 - val_loss: 14.9996 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "57/57 [==============================] - 4s 78ms/step - loss: 14.8900 - accuracy: 0.0000e+00 - val_loss: 14.2979 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "57/57 [==============================] - 5s 80ms/step - loss: 14.1537 - accuracy: 0.0000e+00 - val_loss: 13.3100 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "57/57 [==============================] - 4s 78ms/step - loss: 13.4124 - accuracy: 0.0000e+00 - val_loss: 12.5811 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "57/57 [==============================] - 4s 78ms/step - loss: 12.6200 - accuracy: 5.5586e-04 - val_loss: 11.8244 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "57/57 [==============================] - 5s 79ms/step - loss: 11.9038 - accuracy: 0.0022 - val_loss: 11.0032 - val_accuracy: 0.0037\n",
            "Epoch 28/50\n",
            "57/57 [==============================] - 4s 78ms/step - loss: 11.1095 - accuracy: 0.0082 - val_loss: 10.1418 - val_accuracy: 0.0188\n",
            "Epoch 29/50\n",
            "57/57 [==============================] - 4s 76ms/step - loss: 10.3634 - accuracy: 0.0165 - val_loss: 9.3050 - val_accuracy: 0.0500\n",
            "Epoch 30/50\n",
            "57/57 [==============================] - 4s 79ms/step - loss: 9.6300 - accuracy: 0.0321 - val_loss: 8.7674 - val_accuracy: 0.0550\n",
            "Epoch 31/50\n",
            "57/57 [==============================] - 4s 77ms/step - loss: 8.9477 - accuracy: 0.0456 - val_loss: 8.0759 - val_accuracy: 0.0600\n",
            "Epoch 32/50\n",
            "57/57 [==============================] - 4s 77ms/step - loss: 8.3471 - accuracy: 0.0534 - val_loss: 7.4784 - val_accuracy: 0.0625\n",
            "Epoch 33/50\n",
            "57/57 [==============================] - 4s 79ms/step - loss: 7.7181 - accuracy: 0.0607 - val_loss: 6.8671 - val_accuracy: 0.0688\n",
            "Epoch 34/50\n",
            "57/57 [==============================] - 4s 77ms/step - loss: 7.1475 - accuracy: 0.0593 - val_loss: 6.5156 - val_accuracy: 0.0688\n",
            "Epoch 35/50\n",
            "57/57 [==============================] - 4s 77ms/step - loss: 6.6601 - accuracy: 0.0677 - val_loss: 5.8519 - val_accuracy: 0.0787\n",
            "Epoch 36/50\n",
            "57/57 [==============================] - 4s 78ms/step - loss: 6.1726 - accuracy: 0.0775 - val_loss: 5.5148 - val_accuracy: 0.0913\n",
            "Epoch 37/50\n",
            "57/57 [==============================] - 4s 77ms/step - loss: 5.7244 - accuracy: 0.0812 - val_loss: 5.0387 - val_accuracy: 0.0950\n",
            "Epoch 38/50\n",
            "57/57 [==============================] - 4s 78ms/step - loss: 5.3327 - accuracy: 0.0877 - val_loss: 4.7558 - val_accuracy: 0.1075\n",
            "Epoch 39/50\n",
            "57/57 [==============================] - 4s 79ms/step - loss: 5.0151 - accuracy: 0.0953 - val_loss: 4.4353 - val_accuracy: 0.1163\n",
            "Epoch 40/50\n",
            "57/57 [==============================] - 4s 76ms/step - loss: 4.6517 - accuracy: 0.0966 - val_loss: 4.0723 - val_accuracy: 0.1388\n",
            "Epoch 41/50\n",
            "57/57 [==============================] - 4s 77ms/step - loss: 4.3483 - accuracy: 0.1137 - val_loss: 3.8390 - val_accuracy: 0.1612\n",
            "Epoch 42/50\n",
            "57/57 [==============================] - 4s 77ms/step - loss: 4.0417 - accuracy: 0.1183 - val_loss: 3.5945 - val_accuracy: 0.1675\n",
            "Epoch 43/50\n",
            "57/57 [==============================] - 4s 77ms/step - loss: 3.8223 - accuracy: 0.1270 - val_loss: 3.3612 - val_accuracy: 0.2050\n",
            "Epoch 44/50\n",
            "57/57 [==============================] - 4s 79ms/step - loss: 3.5756 - accuracy: 0.1367 - val_loss: 3.2094 - val_accuracy: 0.2225\n",
            "Epoch 45/50\n",
            "57/57 [==============================] - 4s 78ms/step - loss: 3.3805 - accuracy: 0.1513 - val_loss: 2.9823 - val_accuracy: 0.2350\n",
            "Epoch 46/50\n",
            "57/57 [==============================] - 4s 77ms/step - loss: 3.1924 - accuracy: 0.1613 - val_loss: 2.8550 - val_accuracy: 0.2400\n",
            "Epoch 47/50\n",
            "57/57 [==============================] - 5s 79ms/step - loss: 2.9962 - accuracy: 0.1738 - val_loss: 2.6904 - val_accuracy: 0.2900\n",
            "Epoch 48/50\n",
            "57/57 [==============================] - 4s 76ms/step - loss: 2.8117 - accuracy: 0.1930 - val_loss: 2.5256 - val_accuracy: 0.3250\n",
            "Epoch 49/50\n",
            "57/57 [==============================] - 4s 77ms/step - loss: 2.6499 - accuracy: 0.2083 - val_loss: 2.4417 - val_accuracy: 0.3338\n",
            "Epoch 50/50\n",
            "57/57 [==============================] - 4s 78ms/step - loss: 2.5369 - accuracy: 0.2221 - val_loss: 2.2388 - val_accuracy: 0.3750\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78df64d89840>"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict"
      ],
      "metadata": {
        "id": "hhsAPQJBSGLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(valid_x)\n",
        "decoded = K.get_value(K.ctc_decode(preds, input_length=np.ones(preds.shape[0])*preds.shape[1],\n",
        "                                   greedy=True)[0][0])\n",
        "\n",
        "prediction = []\n",
        "for i in range(valid_size):\n",
        "    prediction.append(num_to_label(decoded[i]))"
      ],
      "metadata": {
        "id": "CwfnUGFISEmK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72f7ff0d-a3e1-4f03-84aa-c4a8b7d33875"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 1s 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = valid.loc[0:valid_size, 'IDENTITY']\n",
        "correct_char = 0\n",
        "total_char = 0\n",
        "correct = 0\n",
        "\n",
        "for i in range(valid_size):\n",
        "    pr = prediction[i]\n",
        "    tr = y_true[i]\n",
        "    total_char += len(tr)\n",
        "\n",
        "    for j in range(min(len(tr), len(pr))):\n",
        "        if tr[j] == pr[j]:\n",
        "            correct_char += 1\n",
        "\n",
        "    if pr == tr :\n",
        "        correct += 1\n",
        "\n",
        "print('Correct characters predicted : %.2f%%' %(correct_char*100/total_char))\n",
        "print('Correct words predicted      : %.2f%%' %(correct*100/valid_size))"
      ],
      "metadata": {
        "id": "gvRdsv9_SHde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0dc05d6-2bd9-4d66-bbd2-20a795c768f3"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct characters predicted : 68.04%\n",
            "Correct words predicted      : 55.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_final.save(\"wordModelOCR2.h5\")"
      ],
      "metadata": {
        "id": "qrLFMEHYSKv-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56ce2629-5604-46f2-b936-90de9a812ef5"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict 2"
      ],
      "metadata": {
        "id": "KhWy-D5YSTd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import load_model, Model\n",
        "from keras import backend as K\n",
        "from keras.layers import Input\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model(\"wordModelOCR2.h5\", compile=False)\n",
        "\n",
        "# Define the alphabet and other parameters\n",
        "alphabets = u\"ABCÇDEFGĞHIİJKLMNOÖPRSŞTUÜVYZabcçdefgğhıijklmnoöprsştuüvyz0123456789\\\".,-':;()?/!+& \"\n",
        "max_str_len = 24\n",
        "num_of_timestamps = 64\n",
        "\n",
        "def preprocess(img):\n",
        "    (h, w) = img.shape\n",
        "    final_img = np.ones([64, 256]) * 255  # blank white image\n",
        "\n",
        "    # crop\n",
        "    if w > 256:\n",
        "        img = img[:, :256]\n",
        "    if h > 64:\n",
        "        img = img[:64, :]\n",
        "\n",
        "    final_img[:h, :w] = img\n",
        "    return cv2.rotate(final_img, cv2.ROTATE_90_CLOCKWISE)\n",
        "\n",
        "def num_to_label(num):\n",
        "    ret = \"\"\n",
        "    for ch in num:\n",
        "        if ch == -1:  # CTC Blank\n",
        "            break\n",
        "        else:\n",
        "            ret += alphabets[ch]\n",
        "    return ret\n",
        "\n",
        "# Create a new model that outputs predictions directly\n",
        "input_data = Input(shape=(256, 64, 1), name='input')\n",
        "y_pred = model.get_layer('softmax').output\n",
        "prediction_model = Model(inputs=model.input[0], outputs=y_pred)\n",
        "\n",
        "# Load and preprocess the new image\n",
        "img_dir = '/content/word_14.png'\n",
        "image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
        "image = preprocess(image)\n",
        "image = image / 255.0\n",
        "\n",
        "# Predict\n",
        "pred = prediction_model.predict(image.reshape(1, 256, 64, 1))\n",
        "decoded = K.get_value(K.ctc_decode(pred, input_length=np.ones(pred.shape[0]) * pred.shape[1],\n",
        "                                   greedy=True)[0][0])\n",
        "\n",
        "print('Predicted text:', num_to_label(decoded[0]))\n"
      ],
      "metadata": {
        "id": "yrvtVph_SLo4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f056d03a-a4b7-4ab6-efc4-c385d6f4c3ec"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Predicted text: Ancak,\n"
          ]
        }
      ]
    }
  ]
}
